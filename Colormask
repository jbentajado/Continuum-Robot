import libjevois as jevois
import cv2
import numpy as np
import time

## Places a color mask to find the specified color target
#
# Add some description of your module here.
#
# @author Adriane Almiranez
# 
# @videomapping YUYV 320 240 45 YUYV 320 240 45 ContinuumRobotics ColorMask
# @email aadrianeb@gmail.com
# @address 123 first street, Los Angeles CA 90012, USA
# @copyright Copyright (C) 2018 by Adriane Almiranez



class ColorMask:
    # ###################################################################################################
    ## Constructor
    def __init__(self):
        # Instantiate a JeVois Timer to measure our processing framerate:
        self.timer = jevois.Timer("processing timer", 100, jevois.LOG_INFO)
        
        # a simple frame counter used to demonstrate sendSerial():
        self.frame = 0
        
        # Instantiate a circular blob detector:
        params = cv2.SimpleBlobDetector_Params()
        params.filterByCircularity = False
        params.filterByArea = True
        params.minArea = 100
        self.detector = cv2.SimpleBlobDetector_create(params)
 
        # Create a morpho kernel (this was not in the original code?)
        self.kernel = np.ones((5,5), np.uint8)
        
    # ###################################################################################################
    ## Process function with USB output
    def process(self, inframe, outframe):
        # Get the next camera image (may block until it is captured) and here convert it to OpenCV BGR. If you need a
        # grayscale image, just use getCvGRAY() instead of getCvBGR(). Also supported are getCvRGB() and getCvRGBA():
        inimg = inframe.getCvBGR()
        
        # Get image width, height:
        height, width, depth = inimg.shape
        
        # Start measuring image processing time (NOTE: does not account for input conversion time):
        self.timer.start()
        
        # filter noise
        blur = cv2.GaussianBlur(inimg, (3, 3), 0, 0)
        hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)
        #blur = cv2.Laplacian(hsv, -1, ksize=5, scale=0.25, delta=127)
        
        #target = "red"
        target = "green"
        #target = "blue"
        
        if target == "red":
            lower=np.array([0,150,0],np.uint8)
            upper=np.array([10,255,255],np.uint8)
        elif target == "green":
            lower = np.array([40,150,0],np.uint8)
            upper = np.array([80,255,255],np.uint8)
        elif target == "blue":
            lower = np.array([100,150,0],np.uint8)
            upper = np.array([140,255,255],np.uint8)
            
        mask = cv2.inRange(hsv, lower, upper)
        mask = cv2.dilate(mask, None, iterations=1)
        res = cv2.bitwise_and(inimg, inimg, mask = mask)
        
        
        ### Addition of Distance Detect---------------------------------------------------------------------
        ### Addition of Distance Detect---------------------------------------------------------------------
        ### Addition of Distance Detect---------------------------------------------------------------------
        
        #-----Image Processing----------------------------------
 
        # Also convert it to grayscale for processing:
        grayImage = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)
        
        # filter noise
        grayImage = cv2.GaussianBlur(grayImage, (3, 3), 0, 0)
        
        # filter noise
        grayImage = cv2.blur(grayImage, (5, 5))
        
        # apply automatic threshold
        ret, grayImage = cv2.threshold(grayImage, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
 
        # background area
        grayImage = cv2.dilate(grayImage, self.kernel, iterations = 1) #self.morphBNo2)
        invBack2 = 255 - grayImage
        
        #-----Blob Detection--------------------------------------------------------------------------------
        
        # blob detection
        keypoints = self.detector.detect(grayImage)
        nrOfBlobs = len(keypoints) #number of items in this object
        
        # draw keypoints
        img_with_keypoints = cv2.drawKeypoints(res, keypoints, np.array([]), (255, 0, 0),
                                              cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)#(B,G,R)
        # draw coordinate system overlay
        
        cv2.line(img_with_keypoints, (0,int(height/2)), (int(width), int(height/2)), (0,0,255), 1) #x line
        cv2.line(img_with_keypoints, (int(width/2),0), (int(width/2), int(height)), (255,0,0), 1) #y line
  
        #-----On Screen Text----------------------------------
 
        # text only appears if at least 1 blob is detected
        if nrOfBlobs > 0:
            i = 0
            # Keypoint calculations
            x = keypoints[i].pt[0]
            y = keypoints[i].pt[1]
            x_center = -x + (width/2)      #160 = 1/2 of screen width
            y_center = y - (height/2)     #120 = 1/2 of screen length
            
            area = keypoints[i].size    #Pixel area and distance are inversely related
            dist = ((1/area)*1000)-2        # Still needs conversion rate
            
            color_cntrl = 255
            if int(x_center) == 0 and int(y_center) == 0 :
                cv2.putText(img_with_keypoints, "Centered!".format(int(dist)),  (10, 55), cv2.FONT_HERSHEY_PLAIN,
                        .75, (0, 255, 0, 0))
                cv2.line(img_with_keypoints, (0,int(height/2)), (int(width), int(height/2)), (0,255,0), 2) #x line
                cv2.line(img_with_keypoints, (int(width/2),0), (int(width/2), int(height)), (0,255,0), 2) #y line
                color_cntrl = 0
                
            else:
                color_cntrl = 255
                
            cv2.putText(img_with_keypoints, "Dist: {} cm".format(int(dist)),  (10, 25), cv2.FONT_HERSHEY_PLAIN,
                        1, (0, 255, color_cntrl, color_cntrl))
            cv2.putText(img_with_keypoints, "X: {}".format(int(x_center)), (10, 35), cv2.FONT_HERSHEY_PLAIN,
                        .75, (0, 255, color_cntrl, color_cntrl))
            cv2.putText(img_with_keypoints, "Y: {}".format(int(y_center)), (10, 45), cv2.FONT_HERSHEY_PLAIN,
                        .75, (0, 255, color_cntrl, color_cntrl))
                        
        ### Addition of Distance Detect---------------------------------------------------------------------
        ### Addition of Distance Detect---------------------------------------------------------------------
        ### Addition of Distance Detect---------------------------------------------------------------------
        
        # setting up 4-panel display
        vertstack1 = np.vstack((inimg, hsv))
        vertstack2 = np.vstack((img_with_keypoints, res))
        quadstack = np.hstack((vertstack1, vertstack2))
        
        outimg = quadstack
        #outimg = mask
        #outimg = grayImage
        
        # Write panel labels:
        cv2.putText(outimg, "Raw img", (3, 40), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255))
        cv2.putText(outimg, "Obj Detect", (340, 40), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255))
        cv2.putText(outimg, "blur", (3, 280), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255))
        cv2.putText(outimg, "Color Mask", (340, 280), cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255))
        
        # Write frames/s info from our timer into the edge map (NOTE: does not account for output conversion time):
        fps = self.timer.stop()
        height = outimg.shape[0]
        width = outimg.shape[1]
        cv2.putText(outimg, fps, (325, height - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255))
        
        # Convert our output image to video output format and send to host over USB:
        outframe.sendCv(outimg)

        # Example of sending some serial output message:
        jevois.sendSerial("DONE frame {}".format(self.frame));
        self.frame += 1
        
    # ###################################################################################################
    ## Process function with no USB output
    def processNoUSB(self, inframe):
        # Get the next camera image (may block until it is captured) and here convert it to OpenCV BGR. If you need a
        # grayscale image, just use getCvGRAY() instead of getCvBGR(). Also supported are getCvRGB() and getCvRGBA():
        inimg = inframe.getCvBGR()
        
        # Get image width, height:
        height, width = inimg.shape
        
        # Start measuring image processing time (NOTE: does not account for input conversion time):
        self.timer.start()
        
        jevois.LINFO("Processing video frame {} now...".format(self.frame))

        # TODO: you should implement some processing.
        # Once you have some results, send serial output messages:

        # Get frames/s info from our timer:
        fps = self.timer.stop()

        # Send a serial output message:
        jevois.sendSerial("DONE frame {} - {}".format(self.frame, fps));
        self.frame += 1
        
    # ###################################################################################################
    ## Parse a serial command forwarded to us by the JeVois Engine, return a string
    def parseSerial(self, str):
        jevois.LINFO("parseserial received command [{}]".format(str))
        if str == "hello":
            return self.hello()
        return "ERR Unsupported command"
    
    # ###################################################################################################
    ## Return a string that describes the custom commands we support, for the JeVois help message
    def supportedCommands(self):
        # use \n seperator if your module supports several commands
        return "hello - print hello using python"

    # ###################################################################################################
    ## Internal method that gets invoked as a custom command
    def hello(self):
        return "Hello from python!"
        
